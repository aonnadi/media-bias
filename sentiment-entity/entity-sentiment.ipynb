{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity sentiment analysis results saved to entity_sentiment_results.csv\n"
     ]
    }
   ],
   "source": [
    "def analyze_entity_sentiment(articles):\n",
    "    api_endpoint = \"https://language.googleapis.com/v1/documents:analyzeEntitySentiment\"\n",
    "    api_key = \"\"  # Replace with your actual API key\n",
    "    \n",
    "    entity_sentiment_results = []  # List to store entity sentiment analysis results\n",
    "    \n",
    "    for idx, article in enumerate(articles, start=1):\n",
    "        text_content = article[\"Text Content\"]\n",
    "        article_title = article[\"Article Title\"]\n",
    "        \n",
    "        # Create the request payload for entity sentiment analysis\n",
    "        data = {\n",
    "            \"document\": {\n",
    "                \"type\": \"PLAIN_TEXT\",\n",
    "                \"content\": text_content\n",
    "            },\n",
    "            \"encodingType\": \"UTF8\",\n",
    "        }\n",
    "        \n",
    "        params = {\n",
    "            \"key\": api_key\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Send the HTTP POST request for entity sentiment analysis\n",
    "        response = requests.post(api_endpoint, params=params, headers=headers, data=json.dumps(data))\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            entity_sentiment_data = response.json()\n",
    "            # Get the entity sentiment analysis results\n",
    "            entity_sentiments = entity_sentiment_data.get(\"entities\", [])\n",
    "            for entity_sentiment in entity_sentiments:\n",
    "                entity_sentiment_result = {\n",
    "                    \"Article Number\": idx,\n",
    "                    \"Article Title\": article_title,\n",
    "                    \"Entity Name\": entity_sentiment[\"name\"],\n",
    "                    \"Entity Type\": entity_sentiment[\"type\"],\n",
    "                    \"Entity Salience\": entity_sentiment[\"salience\"],\n",
    "                    \"Entity Sentiment Score\": entity_sentiment[\"sentiment\"][\"score\"],\n",
    "                    \"Entity Sentiment Magnitude\": entity_sentiment[\"sentiment\"][\"magnitude\"]\n",
    "                }\n",
    "                entity_sentiment_results.append(entity_sentiment_result)\n",
    "        \n",
    "    # Analyze mentions for the entity\n",
    "                # mentions = entity_sentiment.get(\"mentions\", [])\n",
    "                # for mention in mentions:\n",
    "                #     mention_result = {\n",
    "                #         \"Entity Name\": entity_sentiment[\"name\"],\n",
    "                #         \"Mention Content\": mention[\"text\"][\"content\"],\n",
    "                #         \"Mention Type\": mention[\"type\"],\n",
    "                #     }\n",
    "                #     entity_sentiment_results.append(mention_result)\n",
    "        else:\n",
    "            print(f\"Error for Article {idx}: {response.status_code} - {response.text}\")\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    # Save the entity sentiment analysis results to a CSV file\n",
    "    csv_file = \"entity_sentiment_results.csv\"\n",
    "    csv_headers = [\"Article Number\", \"Article Title\", \"Entity Name\", \"Entity Type\", \"Entity Salience\", \"Entity Sentiment Score\", \"Entity Sentiment Magnitude\"]\n",
    "    \n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=csv_headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(entity_sentiment_results)\n",
    "    \n",
    "    print(f\"Entity sentiment analysis results saved to {csv_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read articles and their text content from a CSV file\n",
    "    articles = []\n",
    "    with open('articles.csv', mode='r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            articles.append({\"Article Title\": row['Article Title'], \"Text Content\": row['Text Content']})\n",
    "    \n",
    "    analyze_entity_sentiment(articles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
